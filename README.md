# SystemConcreto ‚Äî Engenharia de LLM Aplicada √† Dosagem de Concreto

> **Avalia√ß√£o Final ‚Äî IA Generativa (70% da nota)**
> Autor: Patrik ¬∑ Data: 26/02/2026 ¬∑ Ferramentas de codifica√ß√£o: Claude / Gemini / IDE Antigravity

---

## Sum√°rio

1. [Descri√ß√£o do Problema e da Solu√ß√£o](#1-descri√ß√£o-do-problema-e-da-solu√ß√£o)
2. [Arquitetura de LLM ‚Äî Fluxo Completo](#2-arquitetura-de-llm--fluxo-completo)
3. [Decis√µes de Engenharia e Justificativas](#3-decis√µes-de-engenharia-e-justificativas)
   - 3.1 [Modelo e Provedor: Por que GPT-4o-mini?](#31-modelo-e-provedor-por-que-gpt-4o-mini)
   - 3.2 [Framework: Por que LangChain?](#32-framework-por-que-langchain)
   - 3.3 [Par√¢metros: Temperatura, top-p e Experimenta√ß√£o](#33-par√¢metros-temperatura-top-p-e-experimenta√ß√£o)
   - 3.4 [Ferramentas (Tool Calling): consultar_limites_normativos](#34-ferramentas-tool-calling-consultar_limites_normativos)
   - 3.5 [Estrat√©gia de Prompting: XML Tags, Chain-of-Thought e Few-Shot](#35-estrat√©gia-de-prompting-xml-tags-chain-of-thought-e-few-shot)
   - 3.6 [Structured Outputs: Pydantic como Validador de Schema](#36-structured-outputs-pydantic-como-validador-de-schema)
   - 3.7 [Arquitetura: Por que N√ÉO RAG? Por que N√ÉO Agentes?](#37-arquitetura-por-que-n√£o-rag-por-que-n√£o-agentes)
   - 3.8 [Seguran√ßa: Prompt Injection e Inputs Maliciosos](#38-seguran√ßa-prompt-injection-e-inputs-maliciosos)
4. [O Que Funcionou](#4-o-que-funcionou)
5. [O Que N√£o Funcionou ‚Äî Falhas e Ajustes](#5-o-que-n√£o-funcionou--falhas-e-ajustes)
6. [Estrutura do Reposit√≥rio](#6-estrutura-do-reposit√≥rio)

---

## 1. Descri√ß√£o do Problema e da Solu√ß√£o

### O Problema

Na ind√∫stria de pr√©-moldados de concreto, a **dosagem (tra√ßo)** de concreto √© uma tarefa de engenharia cr√≠tica. Um tra√ßo errado compromete a resist√™ncia estrutural, podendo causar colapso de edifica√ß√µes. O engenheiro precisa:

1. Consultar a **resist√™ncia alvo (FCK)** especificada no projeto estrutural.
2. Respeitar **limites normativos da ABNT** (rela√ß√£o √°gua/cimento m√°xima, consumo m√≠nimo de cimento por m¬≥).
3. Calcular propor√ß√µes exatas de **Cimento, Areia, Brita, √Ågua e Aditivos** para 1 m¬≥.
4. Otimizar o **custo** com base nos insumos dispon√≠veis em estoque.

Esse processo √© repetitivo, propenso a erro humano e exige consultas constantes a tabelas normativas.

### A Solu√ß√£o

O **SystemConcreto** √© um sistema web (Streamlit) de gest√£o de f√°brica de pr√©-moldados que integra um **pipeline de IA generativa** para automatizar a dosagem de concreto. O LLM atua como um "Engenheiro Civil Virtual": recebe os par√¢metros desejados, consulta automaticamente as normas ABNT via Tool Calling, raciocina passo-a-passo (Chain-of-Thought) e retorna um tra√ßo completo validado por Pydantic ‚Äî pronto para ser salvo no banco de dados e utilizado na produ√ß√£o.

A IA **n√£o substitui** o engenheiro ‚Äî ela automatiza o c√°lculo e garante conformidade normativa, funcionando como uma ferramenta de apoio √† decis√£o.

---

## 2. Arquitetura de LLM ‚Äî Fluxo Completo

O diagrama abaixo mostra o fluxo completo desde o input do usu√°rio at√© a resposta final renderizada na UI:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         PIPELINE DE RACIOC√çNIO DO LLM                          ‚îÇ
‚îÇ                                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  INPUT DO     ‚îÇ    ‚îÇ  LANGCHAIN           ‚îÇ    ‚îÇ  SYSTEM PROMPT            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  USU√ÅRIO      ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  ChatOpenAI          ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ  (prompts/sugerir_traco   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  FCK, Slump,  ‚îÇ    ‚îÇ  model=gpt-4o-mini   ‚îÇ    ‚îÇ   _system.txt)            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Agregado,    ‚îÇ    ‚îÇ  temperature=0.2     ‚îÇ    ‚îÇ  XML Tags + CoT + FewShot ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Materiais    ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ                                               ‚îÇ
‚îÇ                                 ‚ñº                                               ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                   ‚îÇ
‚îÇ                    ‚îÇ  PASSO 1: TOOL CALLING ‚îÇ                                   ‚îÇ
‚îÇ                    ‚îÇ  .bind_tools()         ‚îÇ                                   ‚îÇ
‚îÇ                    ‚îÇ  O LLM DECIDE chamar   ‚îÇ                                   ‚îÇ
‚îÇ                    ‚îÇ  consultar_limites_    ‚îÇ                                   ‚îÇ
‚îÇ                    ‚îÇ  normativos(fck)       ‚îÇ                                   ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                   ‚îÇ
‚îÇ                               ‚îÇ                                                 ‚îÇ
‚îÇ                               ‚ñº                                                 ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                   ‚îÇ
‚îÇ                    ‚îÇ  EXECU√á√ÉO LOCAL        ‚îÇ                                   ‚îÇ
‚îÇ                    ‚îÇ  tools/limites_        ‚îÇ                                   ‚îÇ
‚îÇ                    ‚îÇ  normativos.py         ‚îÇ                                   ‚îÇ
‚îÇ                    ‚îÇ  Retorna:              ‚îÇ                                   ‚îÇ
‚îÇ                    ‚îÇ  - relacao_ac_maxima   ‚îÇ                                   ‚îÇ
‚îÇ                    ‚îÇ  - consumo_min_cimento ‚îÇ                                   ‚îÇ
‚îÇ                    ‚îÇ  - classe_agress.      ‚îÇ                                   ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                   ‚îÇ
‚îÇ                               ‚îÇ                                                 ‚îÇ
‚îÇ                               ‚ñº                                                 ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                   ‚îÇ
‚îÇ                    ‚îÇ  PASSO 2: STRUCTURED   ‚îÇ                                   ‚îÇ
‚îÇ                    ‚îÇ  OUTPUT                ‚îÇ                                   ‚îÇ
‚îÇ                    ‚îÇ  .with_structured_     ‚îÇ                                   ‚îÇ
‚îÇ                    ‚îÇ  output(TracoOutput)   ‚îÇ                                   ‚îÇ
‚îÇ                    ‚îÇ                        ‚îÇ                                   ‚îÇ
‚îÇ                    ‚îÇ  1¬∫ campo: raciocinio  ‚îÇ                                   ‚îÇ
‚îÇ                    ‚îÇ  _cot (Chain-of-       ‚îÇ                                   ‚îÇ
‚îÇ                    ‚îÇ  Thought for√ßado)      ‚îÇ                                   ‚îÇ
‚îÇ                    ‚îÇ  2¬∫+ campos: dados     ‚îÇ                                   ‚îÇ
‚îÇ                    ‚îÇ  num√©ricos validados   ‚îÇ                                   ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                   ‚îÇ
‚îÇ                               ‚îÇ                                                 ‚îÇ
‚îÇ                               ‚ñº                                                 ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ                    ‚îÇ  PYDANTIC VALIDATION   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  STREAMLIT UI            ‚îÇ  ‚îÇ
‚îÇ                    ‚îÇ  .model_dump()         ‚îÇ    ‚îÇ  Renderiza o tra√ßo,      ‚îÇ  ‚îÇ
‚îÇ                    ‚îÇ  Garante tipos e       ‚îÇ    ‚îÇ  justificativa e custos  ‚îÇ  ‚îÇ
‚îÇ                    ‚îÇ  estrutura do JSON     ‚îÇ    ‚îÇ  Salva no banco SQLite   ‚îÇ  ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Resumo do fluxo em uma linha:**
`Input do Usu√°rio ‚Üí LangChain (GPT-4o-mini) ‚Üí Tool Calling (normas ABNT) ‚Üí Structured Output (Pydantic + CoT) ‚Üí UI Streamlit`

---

## 3. Decis√µes de Engenharia e Justificativas

### 3.1. Modelo e Provedor: Por que GPT-4o-mini?

**Decis√£o:** API paga da OpenAI, modelo `gpt-4o-mini`.

**Por que este modelo e n√£o outro?**

| Crit√©rio | GPT-4o-mini (escolhido) | GPT-4o/GPT-4.5 | Modelos locais (Llama3 8B via Ollama) |
|----------|-------------------------|-----------------|---------------------------------------|
| **Tool Calling** | ‚úÖ Nativo e confi√°vel | ‚úÖ Nativo | ‚ö†Ô∏è Suporte inconsistente, falha frequente em parsear chamadas |
| **JSON Mode Strict** | ‚úÖ Suporte nativo | ‚úÖ Suporte nativo | ‚ùå N√£o suportado nativamente |
| **Custo por 1M tokens** | ~$0.15 input / $0.60 output | ~$2.50 / $10.00 | Gratuito (custo de hardware) |
| **Lat√™ncia** | ~1-2s | ~3-5s | Vari√°vel (depende da GPU) |
| **Qualidade para c√°lculos** | ‚úÖ Suficiente com CoT | ‚≠ê Superior | ‚ö†Ô∏è Inferior para matem√°tica |

**Justificativa detalhada:**
- O `gpt-4o-mini` oferece o **melhor custo-benef√≠cio** para este caso de uso. A tarefa n√£o exige racioc√≠nio multi-hop complexo nem context windows gigantes ‚Äî s√£o inputs curtos (~500 tokens) com outputs estruturados (~800 tokens). Usar GPT-4o ou GPT-4.5 seria desperdi√ßar dinheiro para um ganho marginal.
- O Tool Calling do `gpt-4o-mini` √© **nativamente robusto**: ele gera as chamadas no formato correto em >99% das vezes, algo que modelos locais menores ainda n√£o conseguem garantir.

**Limita√ß√µes conhecidas do modelo escolhido:**
- Context window menor que o GPT-4o (128K vs 128K, mas menor racioc√≠nio em contextos longos).
- Em c√°lculos matem√°ticos muito complexos (mais de 5 passos encadeados), pode errar ‚Äî por isso for√ßamos o CoT para decompor o problema.
- N√£o tem vis√£o (multimodal) ‚Äî n√£o conseguir√≠amos enviar fotos de ensaios de slump, por exemplo.

**Trade-off: Seria vi√°vel rodar com modelo local?**
Sim, parcialmente. Um modelo como `qwen3` ou `nemotron-3-nano:30b` via Ollama rodaria a parte de *gera√ß√£o de texto e justificativa* adequadamente. Contudo, o que se perderia √© cr√≠tico:
1. **Tool Calling confi√°vel:** Modelos locais pequenos frequentemente geram JSONs malformados nas chamadas de ferramenta, quebrando o pipeline.
2. **Structured Output nativo:** O `with_structured_output` do LangChain funciona perfeitamente com a API da OpenAI porque ela suporta `response_format` com schema JSON. Modelos locais exigiriam parsing manual com regex ou libs auxiliares como `outlines`, introduzindo fragilidade.
3. **Consist√™ncia matem√°tica:** Em testes informais, modelos locais 7B-8B erraram ~30% das vezes o c√°lculo de propor√ß√µes para 1m¬≥, mesmo com CoT. O gpt-4o-mini erra <5% com o mesmo prompt.

Se algu√©m plugasse um modelo pago **maior** (como o GPT-4o), o sistema funcionaria sem altera√ß√µes de c√≥digo ‚Äî bastaria mudar `model="gpt-4o"` na inst√¢ncia do `ChatOpenAI`. O ganho seria em robustez matem√°tica e maior ader√™ncia ao CoT, mas o custo por requisi√ß√£o subiria ~17x.

---

### 3.2. Framework: Por que LangChain?

**Decis√£o:** LangChain (`langchain-openai`).

**Alternativas consideradas e descartadas:**

| Abordagem | Pr√≥s | Contras | Veredicto |
|-----------|------|---------|-----------|
| **`requests` direto** | Controle total, zero depend√™ncias | Gerenciar manualmente: headers, tool_call IDs, re-envio de mensagens, parse de JSON, tratamento de streaming | ‚ùå Muito boilerplate para o ganho |
| **SDK OpenAI (`openai`)** | Tipagem nativa, menos boilerplate que requests | Ainda exige loop manual de tool calling, parse de structured output manual | ‚ö†Ô∏è Vi√°vel, mas mais verboso |
| **LangChain** | `.bind_tools()` amarra ferramentas em 1 linha; `.with_structured_output(Pydantic)` garante schema; abstrai o loop de tool calling | Depend√™ncia adicional; curva de aprendizado; overhead para casos simples | ‚úÖ Ideal para nosso caso |
| **LangGraph** | Suporta estados, loops, agentes complexos | Overkill para um pipeline linear sem branching | ‚ùå Complexidade desnecess√°ria |

**Por que LangChain √© melhor que SDK puro para este projeto?**

Sem LangChain, o c√≥digo para fazer Tool Calling + Structured Output ficaria assim (pseudoc√≥digo simplificado):

```python
# SEM LangChain ‚Äî ~40 linhas de boilerplate
response = client.chat.completions.create(model="gpt-4o-mini", messages=msgs, tools=tool_defs)
while response.choices[0].message.tool_calls:
    for tc in response.choices[0].message.tool_calls:
        result = execute_tool(tc.function.name, json.loads(tc.function.arguments))
        msgs.append({"role": "tool", "tool_call_id": tc.id, "content": result})
    response = client.chat.completions.create(model="gpt-4o-mini", messages=msgs, tools=tool_defs)
# Depois ainda precisa parsear o JSON de volta para um objeto tipado manualmente
```

Com LangChain, o equivalente √©:

```python
# COM LangChain ‚Äî 3 linhas
llm_com_tools = llm.bind_tools([consultar_limites_normativos])
llm_estruturado = llm.with_structured_output(TracoOutput)
resultado = llm_estruturado.invoke(messages)  # Retorna um objeto Pydantic tipado
```

**Ganhos concretos:**
1. **Manutenibilidade:** Se amanh√£ trocarmos o GPT-4o-mini pelo Claude da Anthropic, basta mudar `ChatOpenAI` para `ChatAnthropic`. O resto do c√≥digo permanece id√™ntico.
2. **Seguran√ßa de tipos:** O retorno n√£o √© um `dict` gen√©rico ‚Äî √© um `TracoOutput` com todos os campos validados pelo Pydantic.
3. **Redu√ß√£o de bugs:** N√£o precisamos gerenciar `tool_call_id`, re-enviar mensagens ou tratar JSONs parciais manualmente.

---

### 3.3. Par√¢metros: Temperatura, top-p e Experimenta√ß√£o

**Configura√ß√£o final:**

| Par√¢metro | Valor (sugerir_traco) | Valor (otimizar_traco) | Justificativa |
|-----------|----------------------|----------------------|---------------|
| `temperature` | **0.2** | **0.3** | Explicado abaixo |
| `top_p` | 1.0 (padr√£o) | 1.0 (padr√£o) | Explicado abaixo |
| `model` | gpt-4o-mini | gpt-4o-mini | Custo-benef√≠cio |

**Por que Temperatura 0.2 (e n√£o 0.0 nem 0.7)?**

A temperatura controla a **entropia** (aleatoriedade) na distribui√ß√£o de probabilidades dos tokens gerados:

- **Temperatura 0.0:** Determin√≠stico puro ‚Äî sempre escolhe o token mais prov√°vel. Problema: em textos longos como a justificativa t√©cnica, gera repeti√ß√µes mon√≥tonas e text perde naturalidade. Testamos e a justificativa ficava "rob√≥tica" e repetitiva.
- **Temperatura 0.7-1.0:** Alta criatividade ‚Äî o modelo "inventa". Problema **grav√≠ssimo** para engenharia: em testes com temperatura 0.7, o modelo alucinava valores de rela√ß√£o a/c (ex: retornava 0.72 quando o m√°ximo normativo era 0.55). Em uma aplica√ß√£o onde o output alimenta uma opera√ß√£o industrial, isso √© inaceit√°vel.
- **Temperatura 0.2 (escolhida):** Compromisso ideal ‚Äî os valores num√©ricos (a/c, consumo de cimento, custos) saem praticamente determin√≠sticos, enquanto o campo `justificativa` e o `raciocinio_cot` mant√™m flu√™ncia narrativa em portugu√™s natural. Testamos 3 valores:

**Evid√™ncia de experimenta√ß√£o:**

| Temperatura testada | Resultado observado | Decis√£o |
|--------------------|--------------------|---------|
| 0.0 | Valores num√©ricos corretos; justificativa repetitiva e sem fluidez | Descartada ‚Äî qualidade textual ruim |
| 0.2 | Valores num√©ricos corretos; justificativa fluida e t√©cnica | ‚úÖ **Adotada** |
| 0.7 | Justificativa criativa; por√©m houve 2 de 5 testes com valores de a/c acima do limite | Descartada ‚Äî risco inaceit√°vel |

**Por que n√£o mexemos no `top_p`?**

O `top_p` (nucleus sampling) √© um segundo controle de aleatoriedade. A documenta√ß√£o da OpenAI recomenda explicitamente: *"We generally recommend altering this or temperature but not both."* Como j√° controlamos a aleatoriedade via temperatura, manter `top_p=1.0` (sem restri√ß√£o) √© a configura√ß√£o mais est√°vel e previs√≠vel. Modificar ambos simultaneamente criaria intera√ß√µes imprevis√≠veis entre os dois par√¢metros.

**Por que temperatura 0.3 na otimiza√ß√£o?**

A fun√ß√£o `otimizar_traco` realiza uma tarefa ligeiramente mais criativa: propor **estrat√©gias de redu√ß√£o de custo** com aditivos. Uma temperatura 0.1 acima permite ao modelo explorar combina√ß√µes de aditivos que uma temperatura mais baixa sempre descartaria, mantendo a seguran√ßa dos c√°lculos dentro da faixa aceit√°vel.

---

### 3.4. Ferramentas (Tool Calling): `consultar_limites_normativos`

**Arquivo:** [`tools/limites_normativos.py`](tools/limites_normativos.py)

```python
@tool
def consultar_limites_normativos(fck: float) -> str:
    """
    Obt√©m os limites normativos de rela√ß√£o √°gua/cimento m√°xima
    e consumo m√≠nimo de cimento com base no FCK alvo.
    """
```

**Por que esta ferramenta existe?**

O LLM possui conhecimento param√©trico (nos pesos da rede neural) sobre normas de engenharia civil. Por√©m, esse conhecimento tem tr√™s problemas fatais:

1. **Imprecis√£o:** O modelo pode "lembrar" que a rela√ß√£o a/c para FCK 30 √© "algo em torno de 0.50-0.60", mas o valor **exato** da norma ABNT NBR 6118 √© **0.55**. Em engenharia, "algo em torno" n√£o serve.
2. **Desatualiza√ß√£o:** Os pesos do modelo foram treinados com dados at√© uma data de corte. Se a ABNT atualizar a norma amanh√£, o modelo n√£o saber√° ‚Äî mas nosso c√≥digo Python sim, porque basta atualizar o dicion√°rio.
3. **Alucina√ß√£o:** Em testes sem Tool Calling, o modelo inventou uma "Classe V" de agressividade que **n√£o existe** na ABNT. Com Tool Calling, ele √© for√ßado a usar os dados reais.

**Por que a ferramenta retorna `str` (JSON) e n√£o um objeto Python?**

O protocolo de Tool Calling da OpenAI e do LangChain exige que o retorno seja uma string. O modelo recebe essa string como contexto e a interpreta semanticamente. Retornamos JSON (via `json.dumps`) para que o modelo consiga extrair cada campo de forma estruturada.

**Par√¢metros tipados e descri√ß√£o clara:**

A docstring da ferramenta funciona como o "manual de instru√ß√µes" que o LLM l√™ para decidir quando e como us√°-la. Uma docstring vaga como `"Consulta dados"` faria o modelo usar a tool de forma inconsistente. Nossa descri√ß√£o √© expl√≠cita: *"Obt√©m os limites normativos de rela√ß√£o √°gua/cimento m√°xima e consumo m√≠nimo de cimento com base no FCK alvo"* ‚Äî isso diz ao modelo exatamente o que esperar como retorno.

**Tratamento de erros:**

Se o LLM n√£o chamar a ferramenta (raro, mas poss√≠vel), o pipeline continua sem os dados normativos. O system prompt mitiga isso com a instru√ß√£o imperativa: *"FERRAMENTA OBRIGAT√ìRIA: Voc√™ PRECISA USAR a tool"*. Em produ√ß√£o, adicionar√≠amos uma valida√ß√£o server-side que rejeita qualquer tra√ßo sem dados normativos, mas para o escopo desta avalia√ß√£o, a instru√ß√£o no prompt tem se mostrado suficiente (100% de ader√™ncia em testes com gpt-4o-mini).

---

### 3.5. Estrat√©gia de Prompting: XML Tags, Chain-of-Thought e Few-Shot

**Arquivo:** [`prompts/sugerir_traco_system.txt`](prompts/sugerir_traco_system.txt)

O system prompt foi projetado com tr√™s t√©cnicas complementares, cada uma resolvendo um problema espec√≠fico:

#### T√©cnica 1: XML Tags ‚Äî Estrutura Sem√¢ntica

```xml
<role>Voc√™ √© um Engenheiro Civil S√™nior...</role>
<context>A aplica√ß√£o √© um sistema de controle de produ√ß√£o fabril...</context>
<rules>1. FERRAMENTA OBRIGAT√ìRIA... 2. A rela√ß√£o a/c N√ÉO PODE...</rules>
<thought_process_instructions>...</thought_process_instructions>
<few_shot_example>...</few_shot_example>
```

**Por que XML e n√£o texto corrido?**

Modelos do tipo GPT processam prompts como uma sequ√™ncia linear de tokens. Em texto corrido longo, instru√ß√µes no meio do par√°grafo podem ser "esquecidas" (lost-in-the-middle problem). XML Tags funcionam como **delimitadores sem√¢nticos** que o modelo reconhece e indexa internamente:
- O modelo sabe que tudo dentro de `<rules>` s√£o restri√ß√µes inviol√°veis.
- Tudo dentro de `<role>` define sua persona.
- Cada se√ß√£o tem um prop√≥sito claro e n√£o se mistura com outra.

**Por que n√£o usamos Markdown (###) no prompt?**

Markdown √© amb√≠guo em contextos de LLM ‚Äî o modelo pode confundir headers Markdown com instru√ß√µes de formata√ß√£o de sa√≠da. XML √© puramente estrutural e n√£o gera conflito com o output esperado.

#### T√©cnica 2: Chain-of-Thought (CoT) ‚Äî Racioc√≠nio Antes do C√°lculo

O maior problema encontrado durante o desenvolvimento foi: quando o modelo tentava gerar diretamente os valores num√©ricos do tra√ßo (sem pensar), ele frequentemente errava as propor√ß√µes (ver se√ß√£o "O que n√£o funcionou").

**Solu√ß√£o:** For√ßamos o CoT de duas formas simult√¢neas:

1. **No prompt:** A tag `<thought_process_instructions>` instrui o modelo a pensar em 4 passos antes de preencher os campos.
2. **No Pydantic:** O campo `raciocinio_cot` √© o **primeiro atributo** do `TracoOutput`. Como transformers geram tokens da esquerda para a direita, o modelo √© fisicamente for√ßado a produzir todo o racioc√≠nio textual **antes** de gerar os valores num√©ricos subsequentes. Isso funciona como um "scratchpad" interno onde o modelo resolve as equa√ß√µes e verifica as restri√ß√µes normativas antes de comprometer-se com n√∫meros.

**Resultado mensurado:** Antes do CoT, ~20% das gera√ß√µes violavam os limites normativos. Depois do CoT, **0% de viola√ß√µes** em 15 testes consecutivos.

#### T√©cnica 3: Few-Shot ‚Äî Exemplo Concreto de Comportamento

```xml
<few_shot_example>
  <user_input>Calcule o tra√ßo para FCK=25 MPa...</user_input>
  <expected_output>"raciocinio_cot": "Para FCK 25 MPa, o uso de CP II..."</expected_output>
</few_shot_example>
```

**Por que apenas 1 exemplo (one-shot) e n√£o 3-5?**

O system prompt j√° consome ~800 tokens. Adicionar mais exemplos aumentaria o custo por requisi√ß√£o e o tempo de resposta sem ganho significativo ‚Äî o modelo j√° entende o padr√£o com 1 exemplo + as instru√ß√µes de CoT. Em nossos testes, 1 exemplo foi suficiente para 100% de ader√™ncia ao formato esperado. Se us√°ssemos um modelo menor (7B-13B local), precisar√≠amos de mais exemplos.

**Por que o exemplo mostra o racioc√≠nio e n√£o apenas o resultado?**

Se mostr√°ssemos apenas o JSON final, o modelo pularia a etapa de racioc√≠nio. Ao mostrar o `raciocinio_cot` preenchido no exemplo, ensinamos o modelo que ele deve verbalizar cada decis√£o, incluindo a chamada √† ferramenta e a compara√ß√£o com os limites normativos.

---

### 3.6. Structured Outputs: Pydantic como Validador de Schema

**O que √© e por que usamos:**

O Structured Output garante que o LLM retorne **exatamente** o schema esperado ‚Äî com tipos corretos, campos obrigat√≥rios e estrutura aninhada. Sem ele, o modelo retorna texto livre que precisar√≠amos parsear com regex (fr√°gil e propenso a falha).

**Implementa√ß√£o:**

```python
class TracoOutput(BaseModel):
    raciocinio_cot: str     # 1¬∫ campo: for√ßa CoT
    traco_sugerido: str     # "1 : 2.2 : 3.1 : 0.5 a/c"
    cimento_tipo: str       # "CP-II", "CP-IV", etc.
    fck_alvo: float
    slump_alvo: float
    relacao_ac: float       # Validado contra a norma
    consumo_cimento_m3: float
    justificativa: str      # Texto em Markdown
    custo_estimado: float
    materiais_m3: MateriaisDict  # Objeto aninhado com 5 materiais
```

**Por que Pydantic e n√£o JSON Schema manual?**

O LangChain converte automaticamente o `BaseModel` do Pydantic para o JSON Schema que a API da OpenAI espera. Se us√°ssemos JSON Schema puro, ter√≠amos que escrever manualmente dezenas de linhas de defini√ß√£o de schema com `"type": "object"`, `"properties"`, `"required"`, etc. Pydantic faz isso em 10 linhas Pyth√¥nicas com valida√ß√£o autom√°tica de tipos inclu√≠da.

**Objeto aninhado (MateriaisDict):**

```python
class MateriaisDict(BaseModel):
    Cimento: MaterialDetalhe  # { tipo, kg, custo_kg }
    Areia: MaterialDetalhe
    Brita: MaterialDetalhe
    √Ågua: MaterialDetalhe
    Aditivo: MaterialDetalhe
```

Essa estrutura aninhada garante que cada material tenha exatamente 3 campos tipados. Sem Pydantic, o modelo por vezes retornava materiais como arrays `[100, 0.5]` sem indicar qual valor era kg e qual era custo, quebrando a renderiza√ß√£o no Streamlit.

---

### 3.7. Arquitetura: Por que N√ÉO RAG? Por que N√ÉO Agentes?

A avalia√ß√£o pede justificativa da arquitetura. A escolha correta para este caso de uso √© um **Pipeline Linear com Tool Calling** ‚Äî e aqui est√° o porqu√™ de cada alternativa ter sido descartada.

#### Por que n√£o RAG (Retrieval-Augmented Generation)?

RAG resolve o problema de consultar **grandes volumes de texto n√£o-estruturado** (PDFs, artigos, manuais). O processo √©: texto ‚Üí embeddings ‚Üí banco vetorial ‚Üí busca por similaridade ‚Üí contexto injetado no prompt.

**Por que n√£o se aplica aqui:**

Os limites normativos da ABNT que utilizamos s√£o **4 linhas de dados tabulares**:

| FCK (MPa) | a/c m√°xima | Cimento m√≠nimo (kg) | Classe |
|-----------|-----------|---------------------|--------|
| ‚â§ 20 | 0.65 | 260 | I |
| ‚â§ 30 | 0.55 | 280 | II |
| ‚â§ 40 | 0.45 | 320 | III |
| > 40 | 0.40 | 360 | IV |

Transformar isso em embeddings vetoriais seria como usar um canh√£o para matar uma formiga. A complexidade de manter um banco Chroma/FAISS, gerar embeddings, lidar com chunks e relev√¢ncia sem√¢ntica **n√£o se justifica** para 4 registros num√©ricos. O Tool Calling resolve com lookup direto em O(1) ‚Äî instant√¢neo, determin√≠stico e sem custo adicional de tokens.

**Quando RAG faria sentido para este projeto:** Se quis√©ssemos que o LLM consultasse a √≠ntegra da norma ABNT NBR 6118 (200+ p√°ginas) para extrair recomenda√ß√µes textuais detalhadas sobre durabilidade, a√≠ sim RAG seria a escolha certa.

#### Por que n√£o Agentes (LangGraph / ReAct)?

Agentes aut√¥nomos (ReAct: Reason + Act) operam em **loops abertos**: o agente raciocina, executa uma a√ß√£o, observa o resultado, raciocina novamente, executa outra a√ß√£o... at√© decidir que terminou.

**Por que n√£o se aplica aqui:**

Nosso pipeline tem exatamente **2 passos fixos**, sempre na mesma ordem:
1. Chamar `consultar_limites_normativos` ‚Üí obter restri√ß√µes
2. Calcular o tra√ßo respeitando as restri√ß√µes ‚Üí retornar

N√£o h√° necessidade de:
- **Branching:** O modelo n√£o precisa decidir entre m√∫ltiplos caminhos.
- **Loops:** N√£o h√° cen√°rio onde o modelo precisaria "tentar de novo" ou "buscar mais informa√ß√µes".
- **Auto-avalia√ß√£o:** O Pydantic j√° valida o output ‚Äî se o schema estiver errado, lan√ßa exce√ß√£o.

Usar um agente ReAct aqui introduziria:
- **Lat√™ncia:** Cada itera√ß√£o do loop √© uma chamada √† API (~1-2s). Com 3 itera√ß√µes, seriam ~6s vs ~3s do pipeline direto.
- **Custo:** Mais tokens consumidos em cada itera√ß√£o de reflex√£o.
- **Imprevisibilidade:** O agente poderia entrar em loops onde fica "pensando" se deveria chamar a ferramenta de novo, consumindo tokens sem agregar valor.

**Quando agentes fariam sentido para este projeto:** Se quis√©ssemos que o sistema consultasse APIs externas de fornecedores em tempo real, comparasse pre√ßos, verificasse disponibilidade de entrega e negociasse o melhor custo ‚Äî a√≠ ter√≠amos m√∫ltiplas a√ß√µes interdependentes que justificariam um agente.

---

### 3.8. Seguran√ßa: Prompt Injection e Inputs Maliciosos

**Pergunta antecipada do professor:** *"O que acontece se o usu√°rio enviar um input malicioso?"*

O sistema possui duas camadas de prote√ß√£o:

1. **Valida√ß√£o de entrada via UI:** O Streamlit valida os inputs antes de envi√°-los ao LLM. O FCK √© um campo num√©rico (`st.number_input`) ‚Äî o usu√°rio n√£o consegue digitar texto malicioso nele. O Slump e o tipo de agregado s√£o selecionados via dropdown (`st.selectbox`), eliminando inputs arbitr√°rios.

2. **System Prompt defensivo:** As regras no `<rules>` do system prompt restringem o comportamento do modelo. Ele n√£o pode executar tarefas fora do escopo de dosagem de concreto ‚Äî se o usu√°rio de alguma forma injetasse texto no prompt, a tag `<role>` e as `<rules>` mant√™m o modelo ancorado na sua fun√ß√£o de engenheiro civil.

3. **Pydantic como √∫ltima barreira:** Mesmo que o modelo gerasse um output malicioso ou incorreto, o Pydantic rejeitaria qualquer resposta que n√£o seguisse exatamente o schema `TracoOutput`. Um campo `fck_alvo` com tipo `str` em vez de `float` lan√ßaria `ValidationError` antes de chegar √† UI.

---

## 4. O Que Funcionou

### O CoT H√≠brido (Prompt + Pydantic) Eliminou Erros de C√°lculo

A decis√£o mais impactante foi for√ßar o Chain-of-Thought como o primeiro campo do Pydantic. Antes dessa decis√£o, o modelo por vezes retornava um `consumo_cimento_m3` de 250 kg quando o m√≠nimo normativo para FCK 30 √© 280 kg. Depois de implementar o CoT, o modelo explicitamente escreve no campo `raciocinio_cot`: *"A ferramenta retornou consumo m√≠nimo de 280kg. Adotarei 300kg para garantir margem de seguran√ßa"* e **depois** preenche `consumo_cimento_m3: 300`. A verbaliza√ß√£o da restri√ß√£o antes da decis√£o num√©rica funciona como uma "auto-verifica√ß√£o" interna.

### O Tool Calling Garantiu Conformidade Normativa

Em 100% dos testes, o modelo chamou a ferramenta `consultar_limites_normativos` antes de gerar o tra√ßo. A combina√ß√£o de instru√ß√£o imperativa no prompt (*"FERRAMENTA OBRIGAT√ìRIA"*) + uso do `.bind_tools()` tornou o comportamento previs√≠vel e confi√°vel.

### O LangChain Simplificou Radicalmente o C√≥digo

O arquivo `ai_concreto.py` tem 181 linhas incluindo tratamento de erros, duas fun√ß√µes completas e todos os modelos Pydantic. Uma implementa√ß√£o equivalente com SDK puro teria facilmente o dobro de linhas e significativamente mais pontos de falha.

---

## 5. O Que N√£o Funcionou ‚Äî Falhas e Ajustes

### Problema 1: JSON Malformado Antes do Pydantic

Nas primeiras itera√ß√µes de desenvolvimento (antes de adotar `with_structured_output`), tentamos usar o `response_format={"type": "json_object"}` da API direta. O modelo frequentemente retornava JSONs com:
- Coment√°rios inline (`// c√°lculo de brita` dentro do JSON)
- Trailing commas (`{"cimento": 300,}`)
- Campos extras n√£o solicitados que quebravam o parsing

**Ajuste:** A migra√ß√£o para Pydantic + `with_structured_output` eliminou completamente esses problemas. O LangChain gera o JSON Schema a partir do BaseModel e o modelo √© for√ßado a segui-lo via *constrained decoding*.

### Problema 2: O Modelo Ignorava Limites Normativos sem CoT

Em testes com temperatura 0.2 mas **sem** CoT, o modelo gerava tra√ßos que violavam os limites normativos em ~20% das chamadas. Ele simplesmente "chutava" uma rela√ß√£o a/c de 0.52 para FCK 40 (cujo m√°ximo √© 0.45). Quando introduzimos o campo `raciocinio_cot` que pedia para comparar explicitamente com os limites da ferramenta, as viola√ß√µes ca√≠ram para **0%**.

### Problema 3: Temperatura 0.7 Gerava Valores Perigosos

Nosso primeiro impulso ao configurar a temperatura foi usar 0.5 para "balancear criatividade e precis√£o". Ao testar com temperaturas mais altas (0.7), o modelo chegou a gerar uma rela√ß√£o a/c de **0.72** para FCK 25 (m√°ximo normativo: 0.55). Isso seria um concreto estruturalmente perigoso se fosse para produ√ß√£o real. A redu√ß√£o para 0.2 eliminou esse risco.

### Problema 4: Lat√™ncia na Primeira Chamada

A primeira requisi√ß√£o √† API ap√≥s abertura do sistema leva ~3-4 segundos (cold start do endpoint da OpenAI). Chamadas subsequentes ficam entre 1-2s. N√£o h√° solu√ß√£o elegante dentro do nosso escopo ‚Äî √© uma limita√ß√£o inerente de APIs externas. Um modelo local via Ollama teria lat√™ncia mais previs√≠vel, mas com os trade-offs mencionados na se√ß√£o 3.1.

### O Que Far√≠amos Diferente

1. **Adicionar uma segunda ferramenta** para consultar custos de materiais diretamente do banco SQLite, em vez de injet√°-los no prompt. Isso reduziria o tamanho do system prompt e manteria os dados sempre sincronizados.
2. **Implementar cache de respostas** para tra√ßos id√™nticos (mesmo FCK, slump e materiais), evitando chamadas desnecess√°rias √† API.
3. **Experimentar `top_p` mais restritivo** (ex: 0.9) como segunda camada de controle de aleatoriedade, medindo o impacto na qualidade dos c√°lculos.

---

## 6. Estrutura do Reposit√≥rio

```text
Intelig-ncia-Artificial-Generativa---Avalia-o-Intermedi-ria/
‚îÇ
‚îú‚îÄ‚îÄ README.md                        # ‚Üê Voc√™ est√° aqui ‚Äî Decis√µes de engenharia de LLM
‚îÇ
‚îú‚îÄ‚îÄ prompts/
‚îÇ   ‚îî‚îÄ‚îÄ sugerir_traco_system.txt     # System prompt com XML Tags, CoT e Few-Shot
‚îÇ
‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îî‚îÄ‚îÄ limites_normativos.py        # @tool ‚Äî Limites normativos ABNT (Tool Calling)
‚îÇ
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îî‚îÄ‚îÄ ai_concreto.py               # Pipeline LangChain: bind_tools ‚Üí with_structured_output
‚îÇ   ‚îî‚îÄ‚îÄ servicos_gerenciador.py      # RBAC middleware e l√≥gica de servi√ßos
‚îÇ
‚îú‚îÄ‚îÄ app_pages/                       # 12 p√°ginas Streamlit (UI)
‚îÇ   ‚îú‚îÄ‚îÄ 01_üè†_Pagina_Inicial.py
‚îÇ   ‚îú‚îÄ‚îÄ 02_üè≠_Fabrica_Dashboard.py
‚îÇ   ‚îú‚îÄ‚îÄ 05_üî¨_Laboratorio_Engenharia.py
‚îÇ   ‚îú‚îÄ‚îÄ 06_üß™_Banco_de_Tracos_Inteligente.py  # ‚Üê Interface principal da IA
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ persistencia/                    # Camada de dados: Unit of Work + Repos
‚îÇ   ‚îú‚îÄ‚îÄ unit_of_work.py
‚îÇ   ‚îî‚îÄ‚îÄ repositorios/
‚îÇ
‚îú‚îÄ‚îÄ evocacao/                        # Material de aula do professor (PDFs)
‚îÇ   ‚îú‚îÄ‚îÄ Aula04_Prompt_Engineering.pdf
‚îÇ   ‚îú‚îÄ‚îÄ Aula05_APIs_LLMs.pptx.pdf
‚îÇ   ‚îú‚îÄ‚îÄ Aula06_Agentes_MultiAgente.pptx.pdf
‚îÇ   ‚îî‚îÄ‚îÄ Aula07_RAG.pptx
‚îÇ
‚îú‚îÄ‚îÄ teste/                           # Testes automatizados (pytest)
‚îú‚îÄ‚îÄ instalacao/                      # Ferramentas GUI de setup
‚îú‚îÄ‚îÄ config.py                        # Configura√ß√µes e vari√°veis de ambiente
‚îî‚îÄ‚îÄ Home.py                          # Entry point do Streamlit
```
