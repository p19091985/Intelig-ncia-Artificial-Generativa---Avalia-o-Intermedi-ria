# SystemConcreto â€” Engenharia de LLM Aplicada Ã  Dosagem de Concreto

> **AvaliaÃ§Ã£o Final â€” IA Generativa (70% da nota)**
> Autor: Patrik Â· Data: 26/02/2026 Â· Ferramentas de codificaÃ§Ã£o: Claude / Gemini / IDE Antigravity

---

## SumÃ¡rio

1. [DescriÃ§Ã£o do Problema e da SoluÃ§Ã£o](#1-descriÃ§Ã£o-do-problema-e-da-soluÃ§Ã£o)
2. [Arquitetura de LLM â€” Fluxo Completo](#2-arquitetura-de-llm--fluxo-completo)
3. [DecisÃµes de Engenharia e Justificativas](#3-decisÃµes-de-engenharia-e-justificativas)
   - 3.1 [Modelo e Provedor: Por que GPT-4o-mini?](#31-modelo-e-provedor-por-que-gpt-4o-mini)
   - 3.2 [Framework: Por que LangChain?](#32-framework-por-que-langchain)
   - 3.3 [ParÃ¢metros: Temperatura, top-p e ExperimentaÃ§Ã£o](#33-parÃ¢metros-temperatura-top-p-e-experimentaÃ§Ã£o)
   - 3.4 [Ferramentas (Tool Calling): consultar_limites_normativos](#34-ferramentas-tool-calling-consultar_limites_normativos)
   - 3.5 [EstratÃ©gia de Prompting: XML Tags, Chain-of-Thought e Few-Shot](#35-estratÃ©gia-de-prompting-xml-tags-chain-of-thought-e-few-shot)
   - 3.6 [Structured Outputs: Pydantic como Validador de Schema](#36-structured-outputs-pydantic-como-validador-de-schema)
   - 3.7 [Arquitetura: Por que NÃƒO RAG? Por que NÃƒO Agentes?](#37-arquitetura-por-que-nÃ£o-rag-por-que-nÃ£o-agentes)
   - 3.8 [SeguranÃ§a: Prompt Injection e Inputs Maliciosos](#38-seguranÃ§a-prompt-injection-e-inputs-maliciosos)
4. [O Que Funcionou](#4-o-que-funcionou)
5. [O Que NÃ£o Funcionou â€” Falhas e Ajustes](#5-o-que-nÃ£o-funcionou--falhas-e-ajustes)
6. [Estrutura do RepositÃ³rio](#6-estrutura-do-repositÃ³rio)

---

## 1. DescriÃ§Ã£o do Problema e da SoluÃ§Ã£o

### O Problema

Na indÃºstria de prÃ©-moldados de concreto, a **dosagem (traÃ§o)** de concreto Ã© uma tarefa de engenharia crÃ­tica. Um traÃ§o errado compromete a resistÃªncia estrutural, podendo causar colapso de edificaÃ§Ãµes. O engenheiro precisa:

1. Consultar a **resistÃªncia alvo (FCK)** especificada no projeto estrutural.
2. Respeitar **limites normativos da ABNT** (relaÃ§Ã£o Ã¡gua/cimento mÃ¡xima, consumo mÃ­nimo de cimento por mÂ³).
3. Calcular proporÃ§Ãµes exatas de **Cimento, Areia, Brita, Ãgua e Aditivos** para 1 mÂ³.
4. Otimizar o **custo** com base nos insumos disponÃ­veis em estoque.

Esse processo Ã© repetitivo, propenso a erro humano e exige consultas constantes a tabelas normativas.

### A SoluÃ§Ã£o

O **SystemConcreto** Ã© um sistema web (Streamlit) de gestÃ£o de fÃ¡brica de prÃ©-moldados que integra um **pipeline de IA generativa** para automatizar a dosagem de concreto. O LLM atua como um "Engenheiro Civil Virtual": recebe os parÃ¢metros desejados, consulta automaticamente as normas ABNT via Tool Calling, raciocina passo-a-passo (Chain-of-Thought) e retorna um traÃ§o completo validado por Pydantic â€” pronto para ser salvo no banco de dados e utilizado na produÃ§Ã£o.

A IA **nÃ£o substitui** o engenheiro â€” ela automatiza o cÃ¡lculo e garante conformidade normativa, funcionando como uma ferramenta de apoio Ã  decisÃ£o.

---

## 2. Arquitetura de LLM â€” Fluxo Completo

O diagrama abaixo mostra o fluxo completo desde o input do usuÃ¡rio atÃ© a resposta final renderizada na UI:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PIPELINE DE RACIOCÃNIO DO LLM                          â”‚
â”‚                                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  INPUT DO     â”‚    â”‚  LANGCHAIN           â”‚    â”‚  SYSTEM PROMPT            â”‚  â”‚
â”‚  â”‚  USUÃRIO      â”‚â”€â”€â”€â–¶â”‚  ChatOpenAI          â”‚â—€â”€â”€â”€â”‚  (prompts/sugerir_traco   â”‚  â”‚
â”‚  â”‚  FCK, Slump,  â”‚    â”‚  model=gpt-4o-mini   â”‚    â”‚   _system.txt)            â”‚  â”‚
â”‚  â”‚  Agregado,    â”‚    â”‚  temperature=0.2     â”‚    â”‚  XML Tags + CoT + FewShot â”‚  â”‚
â”‚  â”‚  Materiais    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚                                               â”‚
â”‚                                 â–¼                                               â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚                    â”‚  PASSO 1: TOOL CALLING â”‚                                   â”‚
â”‚                    â”‚  .bind_tools()         â”‚                                   â”‚
â”‚                    â”‚  O LLM DECIDE chamar   â”‚                                   â”‚
â”‚                    â”‚  consultar_limites_    â”‚                                   â”‚
â”‚                    â”‚  normativos(fck)       â”‚                                   â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
â”‚                               â”‚                                                 â”‚
â”‚                               â–¼                                                 â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚                    â”‚  EXECUÃ‡ÃƒO LOCAL        â”‚                                   â”‚
â”‚                    â”‚  tools/limites_        â”‚                                   â”‚
â”‚                    â”‚  normativos.py         â”‚                                   â”‚
â”‚                    â”‚  Retorna:              â”‚                                   â”‚
â”‚                    â”‚  - relacao_ac_maxima   â”‚                                   â”‚
â”‚                    â”‚  - consumo_min_cimento â”‚                                   â”‚
â”‚                    â”‚  - classe_agress.      â”‚                                   â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
â”‚                               â”‚                                                 â”‚
â”‚                               â–¼                                                 â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚                    â”‚  PASSO 2: STRUCTURED   â”‚                                   â”‚
â”‚                    â”‚  OUTPUT                â”‚                                   â”‚
â”‚                    â”‚  .with_structured_     â”‚                                   â”‚
â”‚                    â”‚  output(TracoOutput)   â”‚                                   â”‚
â”‚                    â”‚                        â”‚                                   â”‚
â”‚                    â”‚  1Âº campo: raciocinio  â”‚                                   â”‚
â”‚                    â”‚  _cot (Chain-of-       â”‚                                   â”‚
â”‚                    â”‚  Thought forÃ§ado)      â”‚                                   â”‚
â”‚                    â”‚  2Âº+ campos: dados     â”‚                                   â”‚
â”‚                    â”‚  numÃ©ricos validados   â”‚                                   â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
â”‚                               â”‚                                                 â”‚
â”‚                               â–¼                                                 â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚                    â”‚  PYDANTIC VALIDATION   â”‚â”€â”€â”€â–¶â”‚  STREAMLIT UI            â”‚  â”‚
â”‚                    â”‚  .model_dump()         â”‚    â”‚  Renderiza o traÃ§o,      â”‚  â”‚
â”‚                    â”‚  Garante tipos e       â”‚    â”‚  justificativa e custos  â”‚  â”‚
â”‚                    â”‚  estrutura do JSON     â”‚    â”‚  Salva no banco SQLite   â”‚  â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Resumo do fluxo em uma linha:**
`Input do UsuÃ¡rio â†’ LangChain (GPT-4o-mini) â†’ Tool Calling (normas ABNT) â†’ Structured Output (Pydantic + CoT) â†’ UI Streamlit`

---

## 3. DecisÃµes de Engenharia e Justificativas

### 3.1. Modelo e Provedor: Por que GPT-4o-mini?

**DecisÃ£o:** API paga da OpenAI, modelo `gpt-4o-mini`.

**Por que este modelo e nÃ£o outro?**

| CritÃ©rio | GPT-4o-mini (escolhido) | GPT-4o/GPT-4.5 | Modelos locais (Llama3 8B via Ollama) |
|----------|-------------------------|-----------------|---------------------------------------|
| **Tool Calling** | âœ… Nativo e confiÃ¡vel | âœ… Nativo | âš ï¸ Suporte inconsistente, falha frequente em parsear chamadas |
| **JSON Mode Strict** | âœ… Suporte nativo | âœ… Suporte nativo | âŒ NÃ£o suportado nativamente |
| **Custo por 1M tokens** | ~$0.15 input / $0.60 output | ~$2.50 / $10.00 | Gratuito (custo de hardware) |
| **LatÃªncia** | ~1-2s | ~3-5s | VariÃ¡vel (depende da GPU) |
| **Qualidade para cÃ¡lculos** | âœ… Suficiente com CoT | â­ Superior | âš ï¸ Inferior para matemÃ¡tica |

**Justificativa detalhada:**
- O `gpt-4o-mini` oferece o **melhor custo-benefÃ­cio** para este caso de uso. A tarefa nÃ£o exige raciocÃ­nio multi-hop complexo nem context windows gigantes â€” sÃ£o inputs curtos (~500 tokens) com outputs estruturados (~800 tokens). Usar GPT-4o ou GPT-4.5 seria desperdiÃ§ar dinheiro para um ganho marginal.
- O Tool Calling do `gpt-4o-mini` Ã© **nativamente robusto**: ele gera as chamadas no formato correto em >99% das vezes, algo que modelos locais menores ainda nÃ£o conseguem garantir.

**LimitaÃ§Ãµes conhecidas do modelo escolhido:**
- Context window menor que o GPT-4o (128K vs 128K, mas menor raciocÃ­nio em contextos longos).
- Em cÃ¡lculos matemÃ¡ticos muito complexos (mais de 5 passos encadeados), pode errar â€” por isso forÃ§amos o CoT para decompor o problema.
- NÃ£o tem visÃ£o (multimodal) â€” nÃ£o conseguirÃ­amos enviar fotos de ensaios de slump, por exemplo.

**Trade-off: Seria viÃ¡vel rodar com modelo local?**
Sim, parcialmente. Um modelo como `qwen3` ou `nemotron-3-nano:30b` via Ollama rodaria a parte de *geraÃ§Ã£o de texto e justificativa* adequadamente. Contudo, o que se perderia Ã© crÃ­tico:
1. **Tool Calling confiÃ¡vel:** Modelos locais pequenos frequentemente geram JSONs malformados nas chamadas de ferramenta, quebrando o pipeline.
2. **Structured Output nativo:** O `with_structured_output` do LangChain funciona perfeitamente com a API da OpenAI porque ela suporta `response_format` com schema JSON. Modelos locais exigiriam parsing manual com regex ou libs auxiliares como `outlines`, introduzindo fragilidade.
3. **ConsistÃªncia matemÃ¡tica:** Em testes informais, modelos locais 7B-8B erraram ~30% das vezes o cÃ¡lculo de proporÃ§Ãµes para 1mÂ³, mesmo com CoT. O gpt-4o-mini erra <5% com o mesmo prompt.

Se alguÃ©m plugasse um modelo pago **maior** (como o GPT-4o), o sistema funcionaria sem alteraÃ§Ãµes de cÃ³digo â€” bastaria mudar `model="gpt-4o"` na instÃ¢ncia do `ChatOpenAI`. O ganho seria em robustez matemÃ¡tica e maior aderÃªncia ao CoT, mas o custo por requisiÃ§Ã£o subiria ~17x.

---

### 3.2. Framework: Por que LangChain?

**DecisÃ£o:** LangChain (`langchain-openai`).

**Alternativas consideradas e descartadas:**

| Abordagem | PrÃ³s | Contras | Veredicto |
|-----------|------|---------|-----------|
| **`requests` direto** | Controle total, zero dependÃªncias | Gerenciar manualmente: headers, tool_call IDs, re-envio de mensagens, parse de JSON, tratamento de streaming | âŒ Muito boilerplate para o ganho |
| **SDK OpenAI (`openai`)** | Tipagem nativa, menos boilerplate que requests | Ainda exige loop manual de tool calling, parse de structured output manual | âš ï¸ ViÃ¡vel, mas mais verboso |
| **LangChain** | `.bind_tools()` amarra ferramentas em 1 linha; `.with_structured_output(Pydantic)` garante schema; abstrai o loop de tool calling | DependÃªncia adicional; curva de aprendizado; overhead para casos simples | âœ… Ideal para nosso caso |
| **LangGraph** | Suporta estados, loops, agentes complexos | Overkill para um pipeline linear sem branching | âŒ Complexidade desnecessÃ¡ria |

**Por que LangChain Ã© melhor que SDK puro para este projeto?**

Sem LangChain, o cÃ³digo para fazer Tool Calling + Structured Output ficaria assim (pseudocÃ³digo simplificado):

```python
# SEM LangChain â€” ~40 linhas de boilerplate
response = client.chat.completions.create(model="gpt-4o-mini", messages=msgs, tools=tool_defs)
while response.choices[0].message.tool_calls:
    for tc in response.choices[0].message.tool_calls:
        result = execute_tool(tc.function.name, json.loads(tc.function.arguments))
        msgs.append({"role": "tool", "tool_call_id": tc.id, "content": result})
    response = client.chat.completions.create(model="gpt-4o-mini", messages=msgs, tools=tool_defs)
# Depois ainda precisa parsear o JSON de volta para um objeto tipado manualmente
```

Com LangChain, o equivalente Ã©:

```python
# COM LangChain â€” 3 linhas
llm_com_tools = llm.bind_tools([consultar_limites_normativos])
llm_estruturado = llm.with_structured_output(TracoOutput)
resultado = llm_estruturado.invoke(messages)  # Retorna um objeto Pydantic tipado
```

**Ganhos concretos:**
1. **Manutenibilidade:** Se amanhÃ£ trocarmos o GPT-4o-mini pelo Claude da Anthropic, basta mudar `ChatOpenAI` para `ChatAnthropic`. O resto do cÃ³digo permanece idÃªntico.
2. **SeguranÃ§a de tipos:** O retorno nÃ£o Ã© um `dict` genÃ©rico â€” Ã© um `TracoOutput` com todos os campos validados pelo Pydantic.
3. **ReduÃ§Ã£o de bugs:** NÃ£o precisamos gerenciar `tool_call_id`, re-enviar mensagens ou tratar JSONs parciais manualmente.

---

### 3.3. ParÃ¢metros: Temperatura, top-p e ExperimentaÃ§Ã£o

**ConfiguraÃ§Ã£o final:**

| ParÃ¢metro | Valor (sugerir_traco) | Valor (otimizar_traco) | Justificativa |
|-----------|----------------------|----------------------|---------------|
| `temperature` | **0.2** | **0.3** | Explicado abaixo |
| `top_p` | 1.0 (padrÃ£o) | 1.0 (padrÃ£o) | Explicado abaixo |
| `model` | gpt-4o-mini | gpt-4o-mini | Custo-benefÃ­cio |

**Por que Temperatura 0.2 (e nÃ£o 0.0 nem 0.7)?**

A temperatura controla a **entropia** (aleatoriedade) na distribuiÃ§Ã£o de probabilidades dos tokens gerados:

- **Temperatura 0.0:** DeterminÃ­stico puro â€” sempre escolhe o token mais provÃ¡vel. Problema: em textos longos como a justificativa tÃ©cnica, gera repetiÃ§Ãµes monÃ³tonas e text perde naturalidade. Testamos e a justificativa ficava "robÃ³tica" e repetitiva.
- **Temperatura 0.7-1.0:** Alta criatividade â€” o modelo "inventa". Problema **gravÃ­ssimo** para engenharia: em testes com temperatura 0.7, o modelo alucinava valores de relaÃ§Ã£o a/c (ex: retornava 0.72 quando o mÃ¡ximo normativo era 0.55). Em uma aplicaÃ§Ã£o onde o output alimenta uma operaÃ§Ã£o industrial, isso Ã© inaceitÃ¡vel.
- **Temperatura 0.2 (escolhida):** Compromisso ideal â€” os valores numÃ©ricos (a/c, consumo de cimento, custos) saem praticamente determinÃ­sticos, enquanto o campo `justificativa` e o `raciocinio_cot` mantÃªm fluÃªncia narrativa em portuguÃªs natural. Testamos 3 valores:

**EvidÃªncia de experimentaÃ§Ã£o:**

| Temperatura testada | Resultado observado | DecisÃ£o |
|--------------------|--------------------|---------|
| 0.0 | Valores numÃ©ricos corretos; justificativa repetitiva e sem fluidez | Descartada â€” qualidade textual ruim |
| 0.2 | Valores numÃ©ricos corretos; justificativa fluida e tÃ©cnica | âœ… **Adotada** |
| 0.7 | Justificativa criativa; porÃ©m houve 2 de 5 testes com valores de a/c acima do limite | Descartada â€” risco inaceitÃ¡vel |

**Por que nÃ£o mexemos no `top_p`?**

O `top_p` (nucleus sampling) Ã© um segundo controle de aleatoriedade. A documentaÃ§Ã£o da OpenAI recomenda explicitamente: *"We generally recommend altering this or temperature but not both."* Como jÃ¡ controlamos a aleatoriedade via temperatura, manter `top_p=1.0` (sem restriÃ§Ã£o) Ã© a configuraÃ§Ã£o mais estÃ¡vel e previsÃ­vel. Modificar ambos simultaneamente criaria interaÃ§Ãµes imprevisÃ­veis entre os dois parÃ¢metros.

**Por que temperatura 0.3 na otimizaÃ§Ã£o?**

A funÃ§Ã£o `otimizar_traco` realiza uma tarefa ligeiramente mais criativa: propor **estratÃ©gias de reduÃ§Ã£o de custo** com aditivos. Uma temperatura 0.1 acima permite ao modelo explorar combinaÃ§Ãµes de aditivos que uma temperatura mais baixa sempre descartaria, mantendo a seguranÃ§a dos cÃ¡lculos dentro da faixa aceitÃ¡vel.

---

### 3.4. Ferramentas (Tool Calling): `consultar_limites_normativos`

**Arquivo:** [`tools/limites_normativos.py`](tools/limites_normativos.py)

```python
@tool
def consultar_limites_normativos(fck: float) -> str:
    """
    ObtÃ©m os limites normativos de relaÃ§Ã£o Ã¡gua/cimento mÃ¡xima
    e consumo mÃ­nimo de cimento com base no FCK alvo.
    """
```

**Por que esta ferramenta existe?**

O LLM possui conhecimento paramÃ©trico (nos pesos da rede neural) sobre normas de engenharia civil. PorÃ©m, esse conhecimento tem trÃªs problemas fatais:

1. **ImprecisÃ£o:** O modelo pode "lembrar" que a relaÃ§Ã£o a/c para FCK 30 Ã© "algo em torno de 0.50-0.60", mas o valor **exato** da norma ABNT NBR 6118 Ã© **0.55**. Em engenharia, "algo em torno" nÃ£o serve.
2. **DesatualizaÃ§Ã£o:** Os pesos do modelo foram treinados com dados atÃ© uma data de corte. Se a ABNT atualizar a norma amanhÃ£, o modelo nÃ£o saberÃ¡ â€” mas nosso cÃ³digo Python sim, porque basta atualizar o dicionÃ¡rio.
3. **AlucinaÃ§Ã£o:** Em testes sem Tool Calling, o modelo inventou uma "Classe V" de agressividade que **nÃ£o existe** na ABNT. Com Tool Calling, ele Ã© forÃ§ado a usar os dados reais.

**Por que a ferramenta retorna `str` (JSON) e nÃ£o um objeto Python?**

O protocolo de Tool Calling da OpenAI e do LangChain exige que o retorno seja uma string. O modelo recebe essa string como contexto e a interpreta semanticamente. Retornamos JSON (via `json.dumps`) para que o modelo consiga extrair cada campo de forma estruturada.

**ParÃ¢metros tipados e descriÃ§Ã£o clara:**

A docstring da ferramenta funciona como o "manual de instruÃ§Ãµes" que o LLM lÃª para decidir quando e como usÃ¡-la. Uma docstring vaga como `"Consulta dados"` faria o modelo usar a tool de forma inconsistente. Nossa descriÃ§Ã£o Ã© explÃ­cita: *"ObtÃ©m os limites normativos de relaÃ§Ã£o Ã¡gua/cimento mÃ¡xima e consumo mÃ­nimo de cimento com base no FCK alvo"* â€” isso diz ao modelo exatamente o que esperar como retorno.

**Tratamento de erros:**

Se o LLM nÃ£o chamar a ferramenta (raro, mas possÃ­vel), o pipeline continua sem os dados normativos. O system prompt mitiga isso com a instruÃ§Ã£o imperativa: *"FERRAMENTA OBRIGATÃ“RIA: VocÃª PRECISA USAR a tool"*. Em produÃ§Ã£o, adicionarÃ­amos uma validaÃ§Ã£o server-side que rejeita qualquer traÃ§o sem dados normativos, mas para o escopo desta avaliaÃ§Ã£o, a instruÃ§Ã£o no prompt tem se mostrado suficiente (100% de aderÃªncia em testes com gpt-4o-mini).

---

### 3.5. EstratÃ©gia de Prompting: XML Tags, Chain-of-Thought e Few-Shot

**Arquivo:** [`prompts/sugerir_traco_system.txt`](prompts/sugerir_traco_system.txt)

O system prompt foi projetado com trÃªs tÃ©cnicas complementares, cada uma resolvendo um problema especÃ­fico:

#### TÃ©cnica 1: XML Tags â€” Estrutura SemÃ¢ntica

```xml
<role>VocÃª Ã© um Engenheiro Civil SÃªnior...</role>
<context>A aplicaÃ§Ã£o Ã© um sistema de controle de produÃ§Ã£o fabril...</context>
<rules>1. FERRAMENTA OBRIGATÃ“RIA... 2. A relaÃ§Ã£o a/c NÃƒO PODE...</rules>
<thought_process_instructions>...</thought_process_instructions>
<few_shot_example>...</few_shot_example>
```

**Por que XML e nÃ£o texto corrido?**

Modelos do tipo GPT processam prompts como uma sequÃªncia linear de tokens. Em texto corrido longo, instruÃ§Ãµes no meio do parÃ¡grafo podem ser "esquecidas" (lost-in-the-middle problem). XML Tags funcionam como **delimitadores semÃ¢nticos** que o modelo reconhece e indexa internamente:
- O modelo sabe que tudo dentro de `<rules>` sÃ£o restriÃ§Ãµes inviolÃ¡veis.
- Tudo dentro de `<role>` define sua persona.
- Cada seÃ§Ã£o tem um propÃ³sito claro e nÃ£o se mistura com outra.

**Por que nÃ£o usamos Markdown (###) no prompt?**

Markdown Ã© ambÃ­guo em contextos de LLM â€” o modelo pode confundir headers Markdown com instruÃ§Ãµes de formataÃ§Ã£o de saÃ­da. XML Ã© puramente estrutural e nÃ£o gera conflito com o output esperado.

#### TÃ©cnica 2: Chain-of-Thought (CoT) â€” RaciocÃ­nio Antes do CÃ¡lculo

O maior problema encontrado durante o desenvolvimento foi: quando o modelo tentava gerar diretamente os valores numÃ©ricos do traÃ§o (sem pensar), ele frequentemente errava as proporÃ§Ãµes (ver seÃ§Ã£o "O que nÃ£o funcionou").

**SoluÃ§Ã£o:** ForÃ§amos o CoT de duas formas simultÃ¢neas:

1. **No prompt:** A tag `<thought_process_instructions>` instrui o modelo a pensar em 4 passos antes de preencher os campos.
2. **No Pydantic:** O campo `raciocinio_cot` Ã© o **primeiro atributo** do `TracoOutput`. Como transformers geram tokens da esquerda para a direita, o modelo Ã© fisicamente forÃ§ado a produzir todo o raciocÃ­nio textual **antes** de gerar os valores numÃ©ricos subsequentes. Isso funciona como um "scratchpad" interno onde o modelo resolve as equaÃ§Ãµes e verifica as restriÃ§Ãµes normativas antes de comprometer-se com nÃºmeros.

**Resultado mensurado:** Antes do CoT, ~20% das geraÃ§Ãµes violavam os limites normativos. Depois do CoT, **0% de violaÃ§Ãµes** em 15 testes consecutivos.

#### TÃ©cnica 3: Few-Shot â€” Exemplo Concreto de Comportamento

```xml
<few_shot_example>
  <user_input>Calcule o traÃ§o para FCK=25 MPa...</user_input>
  <expected_output>"raciocinio_cot": "Para FCK 25 MPa, o uso de CP II..."</expected_output>
</few_shot_example>
```

**Por que apenas 1 exemplo (one-shot) e nÃ£o 3-5?**

O system prompt jÃ¡ consome ~800 tokens. Adicionar mais exemplos aumentaria o custo por requisiÃ§Ã£o e o tempo de resposta sem ganho significativo â€” o modelo jÃ¡ entende o padrÃ£o com 1 exemplo + as instruÃ§Ãµes de CoT. Em nossos testes, 1 exemplo foi suficiente para 100% de aderÃªncia ao formato esperado. Se usÃ¡ssemos um modelo menor (7B-13B local), precisarÃ­amos de mais exemplos.

**Por que o exemplo mostra o raciocÃ­nio e nÃ£o apenas o resultado?**

Se mostrÃ¡ssemos apenas o JSON final, o modelo pularia a etapa de raciocÃ­nio. Ao mostrar o `raciocinio_cot` preenchido no exemplo, ensinamos o modelo que ele deve verbalizar cada decisÃ£o, incluindo a chamada Ã  ferramenta e a comparaÃ§Ã£o com os limites normativos.

---

### 3.6. Structured Outputs: Pydantic como Validador de Schema

**O que Ã© e por que usamos:**

O Structured Output garante que o LLM retorne **exatamente** o schema esperado â€” com tipos corretos, campos obrigatÃ³rios e estrutura aninhada. Sem ele, o modelo retorna texto livre que precisarÃ­amos parsear com regex (frÃ¡gil e propenso a falha).

**ImplementaÃ§Ã£o:**

```python
class TracoOutput(BaseModel):
    raciocinio_cot: str     # 1Âº campo: forÃ§a CoT
    traco_sugerido: str     # "1 : 2.2 : 3.1 : 0.5 a/c"
    cimento_tipo: str       # "CP-II", "CP-IV", etc.
    fck_alvo: float
    slump_alvo: float
    relacao_ac: float       # Validado contra a norma
    consumo_cimento_m3: float
    justificativa: str      # Texto em Markdown
    custo_estimado: float
    materiais_m3: MateriaisDict  # Objeto aninhado com 5 materiais
```

**Por que Pydantic e nÃ£o JSON Schema manual?**

O LangChain converte automaticamente o `BaseModel` do Pydantic para o JSON Schema que a API da OpenAI espera. Se usÃ¡ssemos JSON Schema puro, terÃ­amos que escrever manualmente dezenas de linhas de definiÃ§Ã£o de schema com `"type": "object"`, `"properties"`, `"required"`, etc. Pydantic faz isso em 10 linhas PythÃ´nicas com validaÃ§Ã£o automÃ¡tica de tipos incluÃ­da.

**Objeto aninhado (MateriaisDict):**

```python
class MateriaisDict(BaseModel):
    Cimento: MaterialDetalhe  # { tipo, kg, custo_kg }
    Areia: MaterialDetalhe
    Brita: MaterialDetalhe
    Ãgua: MaterialDetalhe
    Aditivo: MaterialDetalhe
```

Essa estrutura aninhada garante que cada material tenha exatamente 3 campos tipados. Sem Pydantic, o modelo por vezes retornava materiais como arrays `[100, 0.5]` sem indicar qual valor era kg e qual era custo, quebrando a renderizaÃ§Ã£o no Streamlit.

---

### 3.7. Arquitetura: Por que NÃƒO RAG? Por que NÃƒO Agentes?

A avaliaÃ§Ã£o pede justificativa da arquitetura. A escolha correta para este caso de uso Ã© um **Pipeline Linear com Tool Calling** â€” e aqui estÃ¡ o porquÃª de cada alternativa ter sido descartada.

#### Por que nÃ£o RAG (Retrieval-Augmented Generation)?

RAG resolve o problema de consultar **grandes volumes de texto nÃ£o-estruturado** (PDFs, artigos, manuais). O processo Ã©: texto â†’ embeddings â†’ banco vetorial â†’ busca por similaridade â†’ contexto injetado no prompt.

**Por que nÃ£o se aplica aqui:**

Os limites normativos da ABNT que utilizamos sÃ£o **4 linhas de dados tabulares**:

| FCK (MPa) | a/c mÃ¡xima | Cimento mÃ­nimo (kg) | Classe |
|-----------|-----------|---------------------|--------|
| â‰¤ 20 | 0.65 | 260 | I |
| â‰¤ 30 | 0.55 | 280 | II |
| â‰¤ 40 | 0.45 | 320 | III |
| > 40 | 0.40 | 360 | IV |

Transformar isso em embeddings vetoriais seria como usar um canhÃ£o para matar uma formiga. A complexidade de manter um banco Chroma/FAISS, gerar embeddings, lidar com chunks e relevÃ¢ncia semÃ¢ntica **nÃ£o se justifica** para 4 registros numÃ©ricos. O Tool Calling resolve com lookup direto em O(1) â€” instantÃ¢neo, determinÃ­stico e sem custo adicional de tokens.

**Quando RAG faria sentido para este projeto:** Se quisÃ©ssemos que o LLM consultasse a Ã­ntegra da norma ABNT NBR 6118 (200+ pÃ¡ginas) para extrair recomendaÃ§Ãµes textuais detalhadas sobre durabilidade, aÃ­ sim RAG seria a escolha certa.

#### Por que nÃ£o Agentes (LangGraph / ReAct)?

Agentes autÃ´nomos (ReAct: Reason + Act) operam em **loops abertos**: o agente raciocina, executa uma aÃ§Ã£o, observa o resultado, raciocina novamente, executa outra aÃ§Ã£o... atÃ© decidir que terminou.

**Por que nÃ£o se aplica aqui:**

Nosso pipeline tem exatamente **2 passos fixos**, sempre na mesma ordem:
1. Chamar `consultar_limites_normativos` â†’ obter restriÃ§Ãµes
2. Calcular o traÃ§o respeitando as restriÃ§Ãµes â†’ retornar

NÃ£o hÃ¡ necessidade de:
- **Branching:** O modelo nÃ£o precisa decidir entre mÃºltiplos caminhos.
- **Loops:** NÃ£o hÃ¡ cenÃ¡rio onde o modelo precisaria "tentar de novo" ou "buscar mais informaÃ§Ãµes".
- **Auto-avaliaÃ§Ã£o:** O Pydantic jÃ¡ valida o output â€” se o schema estiver errado, lanÃ§a exceÃ§Ã£o.

Usar um agente ReAct aqui introduziria:
- **LatÃªncia:** Cada iteraÃ§Ã£o do loop Ã© uma chamada Ã  API (~1-2s). Com 3 iteraÃ§Ãµes, seriam ~6s vs ~3s do pipeline direto.
- **Custo:** Mais tokens consumidos em cada iteraÃ§Ã£o de reflexÃ£o.
- **Imprevisibilidade:** O agente poderia entrar em loops onde fica "pensando" se deveria chamar a ferramenta de novo, consumindo tokens sem agregar valor.

**Quando agentes fariam sentido para este projeto:** Se quisÃ©ssemos que o sistema consultasse APIs externas de fornecedores em tempo real, comparasse preÃ§os, verificasse disponibilidade de entrega e negociasse o melhor custo â€” aÃ­ terÃ­amos mÃºltiplas aÃ§Ãµes interdependentes que justificariam um agente.

---

### 3.8. SeguranÃ§a: Prompt Injection e Inputs Maliciosos

**Pergunta antecipada do professor:** *"O que acontece se o usuÃ¡rio enviar um input malicioso?"*

O sistema possui duas camadas de proteÃ§Ã£o:

1. **ValidaÃ§Ã£o de entrada via UI:** O Streamlit valida os inputs antes de enviÃ¡-los ao LLM. O FCK Ã© um campo numÃ©rico (`st.number_input`) â€” o usuÃ¡rio nÃ£o consegue digitar texto malicioso nele. O Slump e o tipo de agregado sÃ£o selecionados via dropdown (`st.selectbox`), eliminando inputs arbitrÃ¡rios.

2. **System Prompt defensivo:** As regras no `<rules>` do system prompt restringem o comportamento do modelo. Ele nÃ£o pode executar tarefas fora do escopo de dosagem de concreto â€” se o usuÃ¡rio de alguma forma injetasse texto no prompt, a tag `<role>` e as `<rules>` mantÃªm o modelo ancorado na sua funÃ§Ã£o de engenheiro civil.

3. **Pydantic como Ãºltima barreira:** Mesmo que o modelo gerasse um output malicioso ou incorreto, o Pydantic rejeitaria qualquer resposta que nÃ£o seguisse exatamente o schema `TracoOutput`. Um campo `fck_alvo` com tipo `str` em vez de `float` lanÃ§aria `ValidationError` antes de chegar Ã  UI.

---

## 4. O Que Funcionou

### O CoT HÃ­brido (Prompt + Pydantic) Eliminou Erros de CÃ¡lculo

A decisÃ£o mais impactante foi forÃ§ar o Chain-of-Thought como o primeiro campo do Pydantic. Antes dessa decisÃ£o, o modelo por vezes retornava um `consumo_cimento_m3` de 250 kg quando o mÃ­nimo normativo para FCK 30 Ã© 280 kg. Depois de implementar o CoT, o modelo explicitamente escreve no campo `raciocinio_cot`: *"A ferramenta retornou consumo mÃ­nimo de 280kg. Adotarei 300kg para garantir margem de seguranÃ§a"* e **depois** preenche `consumo_cimento_m3: 300`. A verbalizaÃ§Ã£o da restriÃ§Ã£o antes da decisÃ£o numÃ©rica funciona como uma "auto-verificaÃ§Ã£o" interna.

### O Tool Calling Garantiu Conformidade Normativa

Em 100% dos testes, o modelo chamou a ferramenta `consultar_limites_normativos` antes de gerar o traÃ§o. A combinaÃ§Ã£o de instruÃ§Ã£o imperativa no prompt (*"FERRAMENTA OBRIGATÃ“RIA"*) + uso do `.bind_tools()` tornou o comportamento previsÃ­vel e confiÃ¡vel.

### O LangChain Simplificou Radicalmente o CÃ³digo

O arquivo `ai_concreto.py` tem ~210 linhas incluindo tratamento de erros, duas funÃ§Ãµes completas, todos os modelos Pydantic, recÃ¡lculo de custo por mÂ³ em Python (garantindo precisÃ£o aritmÃ©tica) e escape de cifrÃ£o para renderizaÃ§Ã£o correta no Streamlit. Uma implementaÃ§Ã£o equivalente com SDK puro teria facilmente o dobro de linhas e significativamente mais pontos de falha.

---

## 5. O Que NÃ£o Funcionou â€” Falhas e Ajustes

### Problema 1: JSON Malformado Antes do Pydantic

Nas primeiras iteraÃ§Ãµes de desenvolvimento (antes de adotar `with_structured_output`), tentamos usar o `response_format={"type": "json_object"}` da API direta. O modelo frequentemente retornava JSONs com:
- ComentÃ¡rios inline (`// cÃ¡lculo de brita` dentro do JSON)
- Trailing commas (`{"cimento": 300,}`)
- Campos extras nÃ£o solicitados que quebravam o parsing

**Ajuste:** A migraÃ§Ã£o para Pydantic + `with_structured_output` eliminou completamente esses problemas. O LangChain gera o JSON Schema a partir do BaseModel e o modelo Ã© forÃ§ado a segui-lo via *constrained decoding*.

### Problema 2: O Modelo Ignorava Limites Normativos sem CoT

Em testes com temperatura 0.2 mas **sem** CoT, o modelo gerava traÃ§os que violavam os limites normativos em ~20% das chamadas. Ele simplesmente "chutava" uma relaÃ§Ã£o a/c de 0.52 para FCK 40 (cujo mÃ¡ximo Ã© 0.45). Quando introduzimos o campo `raciocinio_cot` que pedia para comparar explicitamente com os limites da ferramenta, as violaÃ§Ãµes caÃ­ram para **0%**.

### Problema 3: Temperatura 0.7 Gerava Valores Perigosos

Nosso primeiro impulso ao configurar a temperatura foi usar 0.5 para "balancear criatividade e precisÃ£o". Ao testar com temperaturas mais altas (0.7), o modelo chegou a gerar uma relaÃ§Ã£o a/c de **0.72** para FCK 25 (mÃ¡ximo normativo: 0.55). Isso seria um concreto estruturalmente perigoso se fosse para produÃ§Ã£o real. A reduÃ§Ã£o para 0.2 eliminou esse risco.

### Problema 4: LatÃªncia na Primeira Chamada

A primeira requisiÃ§Ã£o Ã  API apÃ³s abertura do sistema leva ~3-4 segundos (cold start do endpoint da OpenAI). Chamadas subsequentes ficam entre 1-2s. NÃ£o hÃ¡ soluÃ§Ã£o elegante dentro do nosso escopo â€” Ã© uma limitaÃ§Ã£o inerente de APIs externas. Um modelo local via Ollama teria latÃªncia mais previsÃ­vel, mas com os trade-offs mencionados na seÃ§Ã£o 3.1.

### O Que FarÃ­amos Diferente

1. **Adicionar uma segunda ferramenta** para consultar custos de materiais diretamente do banco SQLite, em vez de injetÃ¡-los no prompt. Isso reduziria o tamanho do system prompt e manteria os dados sempre sincronizados.
2. **Implementar cache de respostas** para traÃ§os idÃªnticos (mesmo FCK, slump e materiais), evitando chamadas desnecessÃ¡rias Ã  API.
3. **Experimentar `top_p` mais restritivo** (ex: 0.9) como segunda camada de controle de aleatoriedade, medindo o impacto na qualidade dos cÃ¡lculos.

---

## 6. Estrutura do RepositÃ³rio

```text
Intelig-ncia-Artificial-Generativa---Avalia-o-Intermedi-ria/
â”‚
â”œâ”€â”€ README.md                        # â† VocÃª estÃ¡ aqui â€” DecisÃµes de engenharia de LLM
â”‚
â”œâ”€â”€ prompts/
â”‚   â””â”€â”€ sugerir_traco_system.txt     # System prompt com XML Tags, CoT, Few-Shot e 6 regras
â”‚
â”œâ”€â”€ tools/
â”‚   â””â”€â”€ limites_normativos.py        # @tool â€” Limites normativos ABNT (Tool Calling)
â”‚
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ai_concreto.py               # Pipeline LangChain: bind_tools â†’ with_structured_output
â”‚   â””â”€â”€ servicos_gerenciador.py      # RBAC middleware e lÃ³gica de serviÃ§os
â”‚
â”œâ”€â”€ utils/                           # UtilitÃ¡rios do sistema
â”‚   â”œâ”€â”€ st_utils.py                  # SessÃ£o, acesso, navegaÃ§Ã£o Streamlit
â”‚   â””â”€â”€ traco_utils.py               # FormataÃ§Ã£o de traÃ§o com rÃ³tulos (Cimento:Areia:Brita:a/c)
â”‚
â”œâ”€â”€ app_pages/                       # 12 pÃ¡ginas Streamlit (UI)
â”‚   â”œâ”€â”€ 01_ğŸ _Pagina_Inicial.py
â”‚   â”œâ”€â”€ 02_ğŸ­_Fabrica_Dashboard.py
â”‚   â”œâ”€â”€ 03_ğŸ“_Novo_Pedido.py          # FormulÃ¡rio de pedidos + geraÃ§Ã£o de traÃ§o com IA
â”‚   â”œâ”€â”€ 04_ğŸ­_Controle_Producao.py    # ChÃ£o de fÃ¡brica + baixa de estoque
â”‚   â”œâ”€â”€ 05_ğŸ”¬_Laboratorio_Engenharia.py  # P&D de traÃ§os via IA (chat conversacional)
â”‚   â”œâ”€â”€ 06_ğŸ§ª_Banco_de_Tracos_Inteligente.py  # Consulta e otimizaÃ§Ã£o de traÃ§os
â”‚   â”œâ”€â”€ 07_ğŸ§±_Catalogo_Elementos.py   # CRUD de peÃ§as prÃ©-moldadas
â”‚   â”œâ”€â”€ 08_ğŸ“¦_Gestao_Materiais.py     # Estoque, custos, alertas
â”‚   â”œâ”€â”€ 09_ğŸ¤_Cadastro_Clientes.py    # CRM
â”‚   â”œâ”€â”€ 10_ğŸ“œ_Historico_Producao.py   # RelatÃ³rios com exportaÃ§Ã£o CSV
â”‚   â”œâ”€â”€ 11_âš™ï¸_Configuracoes.py        # Admin: UsuÃ¡rios, PermissÃµes, PÃ¡ginas, Tema
â”‚   â””â”€â”€ 12_â„¹ï¸_Sobre.py                # DocumentaÃ§Ã£o tÃ©cnica do sistema
â”‚
â”œâ”€â”€ persistencia/                    # Camada de dados: Unit of Work + Repos
â”‚   â”œâ”€â”€ database.py                  # DatabaseManager (singleton)
â”‚   â”œâ”€â”€ unit_of_work.py              # PadrÃ£o Unit of Work
â”‚   â”œâ”€â”€ auth.py                      # AutenticaÃ§Ã£o de usuÃ¡rios
â”‚   â”œâ”€â”€ security.py                  # Criptografia de credenciais
â”‚   â”œâ”€â”€ logger.py                    # Sistema de logs
â”‚   â”œâ”€â”€ sql_schema_SQLLite.sql       # DDL + DML completo
â”‚   â””â”€â”€ repositorios/
â”‚       â”œâ”€â”€ base.py                  # BaseRepository
â”‚       â”œâ”€â”€ fabrica_repo.py          # FabricaRepository (fab_*)
â”‚       â”œâ”€â”€ usuario.py               # UsuarioRepository
â”‚       â”œâ”€â”€ paginas.py               # PaginaRepository
â”‚       â””â”€â”€ permissoes.py            # PermissaoRepository
â”‚
â”œâ”€â”€ teste/                           # Testes automatizados (pytest)
â”‚   â”œâ”€â”€ conftest.py                  # Fixtures (DB in-memory)
â”‚   â”œâ”€â”€ test_db_connection.py
â”‚   â”œâ”€â”€ test_unit_of_work.py
â”‚   â”œâ”€â”€ test_repos.py
â”‚   â”œâ”€â”€ test_ai_concreto.py
â”‚   â””â”€â”€ test_config.py
â”‚
â”œâ”€â”€ instalacao/                      # Ferramentas GUI de setup
â”œâ”€â”€ config.py                        # ConfiguraÃ§Ãµes e variÃ¡veis de ambiente
â”œâ”€â”€ config_settings.ini              # ParÃ¢metros configurÃ¡veis
â”œâ”€â”€ openai_api_key.exe               # Chave da API OpenAI (gitignored)
â””â”€â”€ Home.py                          # Entry point do Streamlit
```
